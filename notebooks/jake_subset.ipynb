{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for obtaining a \"representative subset\"\n",
    "\n",
    "I need more coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv(\"../data/train_labels.csv\")\n",
    "images.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boilerplate\n",
    "assert os.getcwd().endswith(\"/notebooks\")\n",
    "## delete previous samples\n",
    "shutil.rmtree(\"../jake/sample/\")\n",
    "os.remove(\"../jake/samples.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take random (balanced) subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows that are 0 and 1\n",
    "rows_that_are_0 = images[images.label == 0].index.to_numpy()\n",
    "rows_that_are_1 = images[images.label == 1].index.to_numpy()\n",
    "\n",
    "# shuffle them (to randomly select later)\n",
    "np.random.shuffle(rows_that_are_0)\n",
    "np.random.shuffle(rows_that_are_1)\n",
    "\n",
    "\n",
    "### SELECT TRAINING DATA\n",
    "TRAIN_0_SIZE = 100\n",
    "TRAIN_1_SIZE = 100\n",
    "\n",
    "# select 50 random from each\n",
    "train_subset_that_is_0 = images.loc[rows_that_are_0[:TRAIN_0_SIZE]]\n",
    "train_subset_that_is_1 = images.loc[rows_that_are_1[:TRAIN_1_SIZE]]\n",
    "train_subset = pd.concat([train_subset_that_is_0, train_subset_that_is_1])\n",
    "\n",
    "# copy them to the dump/ folder for colab\n",
    "Path(\"../jake/sample/train/0/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../jake/sample/train/1/\").mkdir(parents=True, exist_ok=True)\n",
    "for row in train_subset.itertuples(index=False):\n",
    "    source_fname = f\"../data/train/{row.id}.tif\"\n",
    "    dest_fname   = f\"../jake/sample/train/{row.label}/{row.id}.tif\"\n",
    "    shutil.copyfile(source_fname, dest_fname)\n",
    "\n",
    "### SELECT TESTING DATA\n",
    "TEST_0_SIZE = 50\n",
    "TEST_1_SIZE = 50\n",
    "\n",
    "# select 50 random from each\n",
    "test_subset_that_is_0 = images.loc[rows_that_are_0[TRAIN_0_SIZE:TRAIN_0_SIZE+TEST_0_SIZE+1]]\n",
    "test_subset_that_is_1 = images.loc[rows_that_are_1[TRAIN_0_SIZE:TRAIN_0_SIZE+TEST_1_SIZE+1]]\n",
    "test_subset = pd.concat([test_subset_that_is_0, test_subset_that_is_1])\n",
    "\n",
    "# copy them to the dump/ folder for colab\n",
    "Path(\"../jake/sample/test/0/\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../jake/sample/test/1/\").mkdir(parents=True, exist_ok=True)\n",
    "for row in test_subset.itertuples(index=False):\n",
    "    source_fname = f\"../data/train/{row.id}.tif\"\n",
    "    dest_fname   = f\"../jake/sample/test/{row.label}/{row.id}.tif\"\n",
    "    shutil.copyfile(source_fname, dest_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip everything\n",
    "shutil.make_archive(\"../jake/samples\", 'zip', \"../jake/sample\") "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
